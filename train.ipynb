{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efectos de la Compresión de Modelos para Sistemas de Recomendación en Dispositivos Móviles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:01:02.456673Z",
     "start_time": "2023-04-19T16:01:02.439538Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cornac\n",
    "import torch.ao.quantization\n",
    "import recommenders\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "\n",
    "from src.compressors import quantization\n",
    "from src.metrics import get_model_size, calculate_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:01:03.428244Z",
     "start_time": "2023-04-19T16:01:03.417243Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# MOVIELENS_DATA_SIZE = '100k'\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 100\n",
    "ENCODER_DIMS = [200]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:01:06.438809Z",
     "start_time": "2023-04-19T16:01:04.329895Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.78k/5.78k [00:01<00:00, 5.65kKB/s]\n"
     ]
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[\"userID\", \"itemID\", \"rating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:01:06.454073Z",
     "start_time": "2023-04-19T16:01:06.440770Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:01:06.595230Z",
     "start_time": "2023-04-19T16:01:06.455091Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040\n",
      "Number of items: 3676\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=1234)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:02:48.551389Z",
     "start_time": "2023-04-19T16:01:06.597227Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ed9e4faba946bf8902a11fd71109dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 66.0911 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=1234,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    # use_gpu=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Calculation (NDCG and Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:05:40.118916Z",
     "start_time": "2023-04-19T16:05:32.160689Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG': 0.4136278628326316, 'Recall@K': 0.13876637955697035, 'Execution_time': 0.0010799661999044475}\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import get_model_size, calculate_metrics\n",
    "\n",
    "base_metrics = calculate_metrics(train,test,bivae)\n",
    "print(base_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:02:56.132256Z",
     "start_time": "2023-04-19T16:02:56.116254Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bivae.save('ckpts')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:02:56.194253Z",
     "start_time": "2023-04-19T16:02:56.148254Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_quatized = torch.ao.quantization.quantize_dynamic(\n",
    "    bivae.bivae,\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:09:06.065613Z",
     "start_time": "2023-04-19T16:08:58.368900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.4136278628326316,\n",
       " 'Recall@K': 0.13876637955697035,\n",
       " 'Execution_time': 0.0007396696002009169}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_bivae = quantization.get_post_dynamic(bivae)\n",
    "quantized_bivae.train_set = train_set\n",
    "\n",
    "calculate_metrics(train,test,quantized_bivae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:18:13.204697Z",
     "start_time": "2023-04-19T16:18:13.155663Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantized_bivae.save(\"ckpts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:17:02.839126Z",
     "start_time": "2023-04-19T16:17:02.820126Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  original  \t Size (KB): 8099.607\n",
      "model:  quantized  \t Size (KB): 2034.063\n",
      "El tamaño del modelo reducido representa un: 25.11310733965241% del modelo original\n"
     ]
    }
   ],
   "source": [
    "original = get_model_size(bivae.bivae, \"original\")\n",
    "quantized = get_model_size(model_quatized,\"quantized\")\n",
    "\n",
    "print(f\"El tamaño del modelo reducido representa un: {(100*(quantized/original))}% del modelo original\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning + Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T16:17:14.263841Z",
     "start_time": "2023-04-19T16:17:14.228749Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon reviews dataset \n",
    "### Clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "if not os.path.exists('./datasets/Clothing_Shoes_and_Jewelry.json.gz'):\n",
    "    print(\"Dont exists!\")\n",
    "    !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Clothing_Shoes_and_Jewelry.json.gz\n",
    "    os.rename('./Clothing_Shoes_and_Jewelry.json.gz', './datasets/Clothing_Shoes_and_Jewelry.json.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size (Dataset size limit due to hardware limitations)\n",
    "DATASET_SIZE = int(0.75e6)\n",
    "\n",
    "# Min interaction per user\n",
    "MIN_RATES = 3\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 100\n",
    "ENCODER_DIMS = [200]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "data = []\n",
    "test_users = []\n",
    "\n",
    "with gzip.open('datasets/Clothing_Shoes_and_Jewelry.json.gz') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l.strip())\n",
    "        # asgining unique id to each user and item\n",
    "        user = int.from_bytes(hashlib.sha256(d['reviewerID'].encode('utf-8')).digest()[:4], 'little')\n",
    "        item = int.from_bytes(hashlib.sha256(d['asin'].encode('utf-8')).digest()[:4], 'little')\n",
    "        rate = d['overall']\n",
    "\n",
    "        entry = {'userID': user, 'itemID': item, 'rating': rate}\n",
    "\n",
    "        data.append(entry)\n",
    "\n",
    "        if len(data) >= DATASET_SIZE:\n",
    "            break\n",
    "\n",
    "data_set = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Filter users with minimal interaction required\n",
    "for u, n in data_set['userID'].value_counts().items():\n",
    "    if n >= MIN_RATES:\n",
    "        test_users.append(u)\n",
    "        \n",
    "data_set = data_set[data_set['userID'].isin(test_users)]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data_set, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 22513\n",
      "Number of items: 2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/Documents/Codigos/MC_6101/proyecto/env/lib/python3.7/site-packages/cornac/data/dataset.py:361: UserWarning: 1136 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=1234)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad92be00e6d44d0883ffd288e7a1cf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 144.2751 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=1234,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    # use_gpu=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Calculation (NDCG and Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG': 0.535461645259503, 'Recall@K': 0.5675428248420948}\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import get_model_size, calculate_metrics\n",
    "\n",
    "base_metrics = calculate_metrics(train,test,bivae)\n",
    "print(base_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quatized = torch.ao.quantization.quantize_dynamic(\n",
    "    bivae.bivae,\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.535461645259503, 'Recall@K': 0.5675428248420948}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_bivae = quantization.get_post_dynamic(bivae)\n",
    "quantized_bivae.train_set = train_set\n",
    "\n",
    "calculate_metrics(train,test,quantized_bivae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  original  \t Size (KB): 20265.239\n",
      "model:  quantized  \t Size (KB): 5075.535\n",
      "El tamaño del modelo reducido representa un: 25.045522532450764% del modelo original\n"
     ]
    }
   ],
   "source": [
    "original = get_model_size(bivae.bivae, \"original\")\n",
    "quantized = get_model_size(model_quatized,\"quantized\")\n",
    "\n",
    "print(f\"El tamaño del modelo reducido representa un: {(100*(quantized/original))}% del modelo original\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning + Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "if not os.path.exists('./datasets/Office_Products.json.gz'):\n",
    "    !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Office_Products.json.gz\n",
    "    os.rename('./Office_Products.json.gz', './datasets/Office_Products.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size (Dataset size limit due to hardware limitations)\n",
    "DATASET_SIZE = int(0.5e6)\n",
    "\n",
    "# Min interaction per user\n",
    "MIN_RATES = 3\n",
    "\n",
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 100\n",
    "ENCODER_DIMS = [200]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "data = []\n",
    "test_users = []\n",
    "\n",
    "with gzip.open('datasets/Office_Products.json.gz') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l.strip())\n",
    "        # asgining unique id to each user and item\n",
    "        user = int.from_bytes(hashlib.sha256(d['reviewerID'].encode('utf-8')).digest()[:4], 'little')\n",
    "        item = int.from_bytes(hashlib.sha256(d['asin'].encode('utf-8')).digest()[:4], 'little')\n",
    "        rate = d['overall']\n",
    "\n",
    "        entry = {'userID': user, 'itemID': item, 'rating': rate}\n",
    "\n",
    "        data.append(entry)\n",
    "\n",
    "        if len(data) >= DATASET_SIZE:\n",
    "            break\n",
    "\n",
    "data_set = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Filter users with minimal interaction required\n",
    "for u, n in data_set['userID'].value_counts().items():\n",
    "    if n >= MIN_RATES:\n",
    "        test_users.append(u)\n",
    "        \n",
    "data_set = data_set[data_set['userID'].isin(test_users)]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data_set, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 15899\n",
      "Number of items: 3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/Documents/Codigos/MC_6101/proyecto/env/lib/python3.7/site-packages/cornac/data/dataset.py:361: UserWarning: 1649 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=1234)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68122c40fcab40d4a3abfc3e96d745a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 143.0167 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=1234,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    # use_gpu=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Calculation (NDCG and Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG': 0.16503002124814123, 'Recall@K': 0.20795829115668152}\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import get_model_size, calculate_metrics\n",
    "\n",
    "base_metrics = calculate_metrics(train,test,bivae)\n",
    "print(base_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivae.save('ckpts')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quatized = torch.ao.quantization.quantize_dynamic(\n",
    "    bivae.bivae,\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.16503002124814123, 'Recall@K': 0.20795829115668152}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_bivae = quantization.get_post_dynamic(bivae)\n",
    "quantized_bivae.train_set = train_set\n",
    "\n",
    "calculate_metrics(train,test,quantized_bivae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_bivae.save(\"ckpts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  original  \t Size (KB): 15516.439\n",
      "model:  quantized  \t Size (KB): 3888.271\n",
      "El tamaño del modelo reducido representa un: 25.059042219674243% del modelo original\n"
     ]
    }
   ],
   "source": [
    "original = get_model_size(bivae.bivae, \"original\")\n",
    "quantized = get_model_size(model_quatized,\"quantized\")\n",
    "\n",
    "print(f\"El tamaño del modelo reducido representa un: {(100*(quantized/original))}% del modelo original\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning + Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "if not os.path.exists('./datasets/Sports_and_Outdoors.json.gz'):\n",
    "    !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Sports_and_Outdoors.json.gz\n",
    "    os.rename('./Sports_and_Outdoors.json.gz', './datasets/Sports_and_Outdoors.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size (Dataset size limit due to hardware limitations)\n",
    "DATASET_SIZE = int(0.5e6)\n",
    "\n",
    "# Min interaction per user\n",
    "MIN_RATES = 3\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 100\n",
    "ENCODER_DIMS = [200]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "data = []\n",
    "test_users = []\n",
    "\n",
    "with gzip.open('datasets/Sports_and_Outdoors.json.gz') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l.strip())\n",
    "        # asgining unique id to each user and item\n",
    "        user = int.from_bytes(hashlib.sha256(d['reviewerID'].encode('utf-8')).digest()[:4], 'little')\n",
    "        item = int.from_bytes(hashlib.sha256(d['asin'].encode('utf-8')).digest()[:4], 'little')\n",
    "        rate = d['overall']\n",
    "\n",
    "        entry = {'userID': user, 'itemID': item, 'rating': rate}\n",
    "\n",
    "        data.append(entry)\n",
    "\n",
    "        if len(data) >= DATASET_SIZE:\n",
    "            break\n",
    "\n",
    "data_set = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Filter users with minimal interaction required\n",
    "for u, n in data_set['userID'].value_counts().items():\n",
    "    if n >= MIN_RATES:\n",
    "        test_users.append(u)\n",
    "        \n",
    "data_set = data_set[data_set['userID'].isin(test_users)]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data_set, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 8600\n",
      "Number of items: 2950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/Documents/Codigos/MC_6101/proyecto/env/lib/python3.7/site-packages/cornac/data/dataset.py:361: UserWarning: 500 duplicated observations are removed!\n",
      "  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=1234)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9103bd0c16a74cd9ab135485c5e990b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 63.2633 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=1234,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    # use_gpu=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiVAECF model is saved to ckpts/BiVAECF/2023-05-30_18-46-33-347004.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ckpts/BiVAECF/2023-05-30_18-46-33-347004.pkl'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bivae.save('ckpts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG': 0.12023943346502655, 'Recall@K': 0.1555377727567522}\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import get_model_size, calculate_metrics\n",
    "\n",
    "base_metrics = calculate_metrics(train,test,bivae)\n",
    "print(base_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quatized = torch.ao.quantization.quantize_dynamic(\n",
    "    bivae.bivae,\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.12023943346502655, 'Recall@K': 0.1555377727567522}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_bivae = quantization.get_post_dynamic(bivae)\n",
    "quantized_bivae.train_set = train_set\n",
    "\n",
    "calculate_metrics(train,test,quantized_bivae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  original  \t Size (KB): 9566.807\n",
      "model:  quantized  \t Size (KB): 2400.847\n",
      "El tamaño del modelo reducido representa un: 25.095593545474472% del modelo original\n"
     ]
    }
   ],
   "source": [
    "original = get_model_size(bivae.bivae, \"original\")\n",
    "quantized = get_model_size(model_quatized,\"quantized\")\n",
    "\n",
    "print(f\"El tamaño del modelo reducido representa un: {(100*(quantized/original))}% del modelo original\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning + Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "if not os.path.exists('./datasets/soc-Epinions1.txt.gz'):\n",
    "    !wget https://snap.stanford.edu/data/soc-Epinions1.txt.gz\n",
    "    os.rename('./soc-Epinions1.txt.gz', './datasets/soc-Epinions1.txt.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size (Dataset size limit due to hardware limitations)\n",
    "DATASET_SIZE = int(1.5e5)\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 100\n",
    "ENCODER_DIMS = [200]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "data = []\n",
    "\n",
    "with gzip.open('datasets/soc-Epinions1.txt.gz') as f:\n",
    "    for i, l in enumerate(f):\n",
    "        if i>3:\n",
    "\n",
    "            d = l.decode().split()\n",
    "            entry = {'userID': int(d[0]), 'itemID': int(d[1]), 'rating': 5}\n",
    "            data.append(entry)\n",
    "\n",
    "        if len(data) >= DATASET_SIZE:\n",
    "            break\n",
    "\n",
    "\n",
    "data_set = pd.DataFrame.from_dict(data)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data_set, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 2000\n",
      "Number of items: 14015\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=1234)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5681d2cc0264a2d984b2ec794f5478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 78.9307 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=1234,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    # use_gpu=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivae.save('ckpts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG': 0.10900177312224939, 'Recall@K': 0.0673371572161086}\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import get_model_size, calculate_metrics\n",
    "\n",
    "base_metrics = calculate_metrics(train,test,bivae)\n",
    "print(base_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quatized = torch.ao.quantization.quantize_dynamic(\n",
    "    bivae.bivae,\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG': 0.10900177312224939, 'Recall@K': 0.0673371572161086}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_bivae = quantization.get_post_dynamic(bivae)\n",
    "quantized_bivae.train_set = train_set\n",
    "\n",
    "calculate_metrics(train,test,quantized_bivae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  original  \t Size (KB): 13138.839\n",
      "model:  quantized  \t Size (KB): 3293.839\n",
      "El tamaño del modelo quatizado representa un: 25.06948292767725% del modelo original\n"
     ]
    }
   ],
   "source": [
    "original = get_model_size(bivae.bivae, \"original\")\n",
    "quantized = get_model_size(model_quatized,\"quantized\")\n",
    "\n",
    "print(f\"El tamaño del modelo quatizado representa un: {(100*(quantized/original))}% del modelo original\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning + Quantization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
